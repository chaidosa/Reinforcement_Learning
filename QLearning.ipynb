{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRBwM+GXEp8qqKZvS8PL0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priteshvermaa/Reinforcement_Learning/blob/main/QLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D4ZHNe31pyp_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initailizing parameters\n",
        "gamma = 0.75 #discont factor\n",
        "alpha = 0.9 # Learning rate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# L1  L2  L3\n",
        "# L4  L5  L6\n",
        "# L7  L8  L9\n",
        "\n",
        "\n",
        "#Set of states\n",
        "location_to_state = {\n",
        "    'L1': 0,\n",
        "    'L2': 1,\n",
        "    'L3': 2,\n",
        "    'L4': 3,\n",
        "    'L5': 4,\n",
        "    'L6': 5,\n",
        "    'L7': 6,\n",
        "    'L8': 7,\n",
        "    'L9': 8\n",
        "}\n",
        "\n",
        "# set of actions\n",
        "actions = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "# Define the rewards\n",
        "rewards = np.array([[0,1,0,0,0,0,0,0,0],\n",
        "              [1,0,1,0,1,0,0,0,0],\n",
        "              [0,1,0,0,0,1,0,0,0],\n",
        "              [0,0,0,0,0,0,1,0,0],\n",
        "              [0,1,0,0,0,0,0,1,0],\n",
        "              [0,0,1,0,0,0,0,0,0],\n",
        "              [0,0,0,1,0,0,0,1,0],\n",
        "              [0,0,0,0,1,0,1,0,1],\n",
        "              [0,0,0,0,0,0,0,1,0]])\n",
        "\n"
      ],
      "metadata": {
        "id": "ygAXh7gvqc1m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maps indices to locations\n",
        "state_to_location = dict((state,location) for location,state in location_to_state.items())\n",
        "state_to_location"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X_okaK9r8nL",
        "outputId": "0824a576-f3db-48ee-e23e-36520e2fa599"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'L1',\n",
              " 1: 'L2',\n",
              " 2: 'L3',\n",
              " 3: 'L4',\n",
              " 4: 'L5',\n",
              " 5: 'L6',\n",
              " 6: 'L7',\n",
              " 7: 'L8',\n",
              " 8: 'L9'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is going to take two arguments:\n",
        "\n",
        "starting location in the warehouse and\n",
        "end location in the warehouse respectively\n",
        "It will return the optimal route for reaching the end location from the starting location in the form of an ordered list (containing the letters)."
      ],
      "metadata": {
        "id": "ne6C95OpsUB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimal_route(start_loc, end_loc):\n",
        "  \n",
        "  #Initializing Q-values\n",
        " \n",
        "\n",
        "  #copy the rewards matrix to new matrix \n",
        "  rewards_copy = np.copy(rewards)\n",
        "\n",
        "  #get the ending state corresponding to the parameter given\n",
        "  ending_state = location_to_state[end_loc]\n",
        "\n",
        "  #set the priority of ending state to the highest\n",
        "  rewards_copy[ending_state, ending_state] = 999\n",
        "\n",
        "\n",
        "  # ************** Q-Learning algorithm****************\n",
        "  Q = np.array(np.zeros([9,9]))\n",
        "  for i in range(1000):\n",
        "    # Pick up a state randomly\n",
        "    current_state = np.random.randint(0, 9)\n",
        "\n",
        "    movable_actions = []\n",
        "    \n",
        "    #ierating through reward matrix and the action greater than 0\n",
        "\n",
        "    for j in range(9):\n",
        "      if rewards_copy[current_state, j] > 0:\n",
        "        movable_actions.append(j)\n",
        "    \n",
        "    # we will choose a state randomly from the movable actions\n",
        "    next_state = np.random.choice(movable_actions)\n",
        "\n",
        "\n",
        "    #Computing the temporal difference \n",
        "    TD = rewards_copy[current_state, next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])] - Q[current_state, next_state]\n",
        "    # TD = rewards_copy[current_state, next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])] - Q[current_state, next_state]\n",
        "    # Update the Q-value using the Bellman equation\n",
        "    Q[current_state, next_state] += alpha * TD\n",
        "\n",
        "    optimal_route = [start_loc]\n",
        "    next_location = start_loc\n",
        "  \n",
        "  # print(Q)\n",
        "  while(next_location != end_loc):\n",
        "      \n",
        "    # Fetch the starting state\n",
        "    start_state = location_to_state[start_loc]\n",
        "\n",
        "    #Fetch the highest Q-value pertaining to starting state\n",
        "    next_state = np.argmax(Q[start_state,])\n",
        "\n",
        "    #We ge the index of the next state\n",
        "    next_location = state_to_location[next_state]\n",
        "\n",
        "    optimal_route.append(next_location)\n",
        "      \n",
        "    start_loc = next_location\n",
        "  return optimal_route  \n",
        "pass\n"
      ],
      "metadata": {
        "id": "ac8lKZlXr_Wq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_optimal_route('L9', 'L1'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8k6nLHHxtbu",
        "outputId": "13122a78-2aca-4bdc-9f2b-fd42439fe922"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3995.9945748  2249.49443881    0.            0.            0.\n",
            "     0.            0.            0.            0.        ]\n",
            " [2997.99474976    0.         1688.12189893    0.         1688.07241758\n",
            "     0.            0.            0.            0.        ]\n",
            " [   0.         2249.49605539    0.            0.            0.\n",
            "  1267.09132149    0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.            0.\n",
            "     0.          951.30901842    0.            0.        ]\n",
            " [   0.         2249.49599614    0.            0.            0.\n",
            "     0.            0.         1267.08143109    0.        ]\n",
            " [   0.            0.         1688.12189686    0.            0.\n",
            "     0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.          714.48037611    0.\n",
            "     0.            0.         1267.08415833    0.        ]\n",
            " [   0.            0.            0.            0.         1688.11261514\n",
            "     0.          951.29051722    0.          951.31077334]\n",
            " [   0.            0.            0.            0.            0.\n",
            "     0.            0.         1267.08415833    0.        ]]\n",
            "['L9', 'L8', 'L5', 'L2', 'L1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iRiSSSRVx0F_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}